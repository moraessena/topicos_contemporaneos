{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando Documentos - Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4301"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://python.langchain.com/v0.2/docs/how_to/#document-loaders\n",
    "# https://python.langchain.com/v0.2/docs/integrations/document_loaders/\n",
    "\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Filtra o conte√∫do da p√°gina por uma classe espec√≠fica\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"container-wrapper\"))\n",
    "\n",
    "# Carrega o conte√∫do da p√°gina\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://cesar.breezy.hr/p/00f79174d8ad-pesquisador-em-inteligencia-artificial-e-sistemas-distribuidos\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "\n",
    "# Carrega o conte√∫do da p√°gina\n",
    "docs = loader.load()\n",
    "\n",
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo Documentos - Splitting/Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://python.langchain.com/v0.2/docs/how_to/#text-splitters\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=500, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requisitos e Qualifica√ß√µes:\n",
      "Doutorado em √°reas correlatas;Compreenda e desenvolva modelos de machine learning e deep learning para resolver desafios complexos de ciberseguran√ßa;Conhecimento em frameworks de machine learning como TensorFlow, PyTorch ou scikit-learn para desenvolver modelos preditivos e de detec√ß√£o de anomalias aplicados √† ciberseguran√ßa;Entenda a arquitetura distribu√≠da dos sistemas e garanta a integra√ß√£o eficiente de solu√ß√µes de IA com aplica√ß√µes em cloud;Habilidade em manipula√ß√£o e visualiza√ß√£o de dados com Pandas, NumPy, Matplotlib e Seaborn para explorar grandes volumes de dados;Experi√™ncia com AWS, Google Cloud ou Azure para projetar e implementar infraestruturas escal√°veis e resilientes;Familiaridade com Kubernetes e Docker para garantir escalabilidade e resili√™ncia de sistemas distribu√≠dos;Experi√™ncia com controle de vers√£o (Git) e reposit√≥rios remotos como GitLab;Ingl√™s avan√ßado para leitura, escrita e comunica√ß√£o, facilitando a colabora√ß√£o com equipes globais.\n"
     ]
    }
   ],
   "source": [
    "print(all_splits[3].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexando - Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/v0.2/docs/how_to/embed_text/\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_documents(all_splits, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"precisa de doutorado para a vaga?\")\n",
    "\n",
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requisitos e Qualifica√ß√µes:\n",
      "Doutorado em √°reas correlatas;Compreenda e desenvolva modelos de machine learning e deep learning para resolver desafios complexos de ciberseguran√ßa;Conhecimento em frameworks de machine learning como TensorFlow, PyTorch ou scikit-learn para desenvolver modelos preditivos e de detec√ß√£o de anomalias aplicados √† ciberseguran√ßa;Entenda a arquitetura distribu√≠da dos sistemas e garanta a integra√ß√£o eficiente de solu√ß√µes de IA com aplica√ß√µes em cloud;Habilidade em manipula√ß√£o e visualiza√ß√£o de dados com Pandas, NumPy, Matplotlib e Seaborn para explorar grandes volumes de dados;Experi√™ncia com AWS, Google Cloud ou Azure para projetar e implementar infraestruturas escal√°veis e resilientes;Familiaridade com Kubernetes e Docker para garantir escalabilidade e resili√™ncia de sistemas distribu√≠dos;Experi√™ncia com controle de vers√£o (Git) e reposit√≥rios remotos como GitLab;Ingl√™s avan√ßado para leitura, escrita e comunica√ß√£o, facilitando a colabora√ß√£o com equipes globais.\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscando e Recuperando Informa√ß√µes - Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"\"\"Voc√™ √© um assistente para tarefas de perguntas e respostas. Use os seguintes trechos de contexto recuperados para responder √† pergunta. Se voc√™ n√£o souber a resposta, apenas diga que n√£o sabe. Use no m√°ximo duas frases e mantenha a resposta concisa e fale apenas o necess√°rio.\n",
    "\n",
    "Pergunta: {question}\n",
    "\n",
    "Contexto: {context}\n",
    "\n",
    "Resposta:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Voc√™ √© um assistente para tarefas de perguntas e respostas. Use os seguintes trechos de contexto recuperados para responder √† pergunta. Se voc√™ n√£o souber a resposta, apenas diga que n√£o sabe. Use no m√°ximo duas frases e mantenha a resposta concisa e fale apenas o necess√°rio.\\n\\nPergunta: alguma pergunta\\n\\nContexto: algum contexto\\n\\nResposta:\\n', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "example_messages = prompt_template.invoke({\n",
    "    \"context\": \"algum contexto\",\n",
    "    \"question\": \"alguma pergunta\"\n",
    "})\n",
    "\n",
    "print(example_messages.to_messages())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando Respostas - Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim, o CESAR oferece plano de sa√∫de como um dos benef√≠cios para os colaboradores. Al√©m disso, h√° tamb√©m plano odontol√≥gico e outros aux√≠lios."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"Tem plano de sa√∫de como benef√≠cio?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exerc√≠cios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 1\n",
    "Fa√ßa um RAG com um pequeno arquivo de texto, contendo informa√ß√µes que, certamente, a LLM n√£o conhe√ßa. Voc√™ dever√° construir o arquivo e enviar para o ambiente de execu√ß√£o. Escolha a forma de chunking apropriada para o seu documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Strateegia possui diversas funcionalidades que visam otimizar a tomada de decis√£o e a inova√ß√£o em comunidades colaborativas. Aqui est√£o algumas das principais:\n",
      "\n",
      "1. **Debates com Agentes Inteligentes**: A plataforma permite que pessoas debatam com agentes inteligentes (IA), facilitando discuss√µes enriquecedoras e trazendo novas perspectivas.\n",
      "\n",
      "2. **Assistentes Inteligentes**: Utilize assistentes executivos, mentores e especialistas de diferentes √°reas para obter insights valiosos e aplicar esses conhecimentos em seus projetos.\n",
      "\n",
      "3. **Modo An√¥nimo Tempor√°rio**: Ative essa funcionalidade para que todos os participantes se sintam √† vontade para expressar opini√µes e discordar, promovendo uma cultura de inova√ß√£o.\n",
      "\n",
      "4. **An√°lises Multidimensionais**: Os assistentes de IA analisam os debates, resumem conte√∫dos e destacam propostas-chave, ajudando a potencializar suas decis√µes com an√°lises precisas.\n",
      "\n",
      "5. **Documentos Prontos para Publica√ß√£o**: Transforme os resultados dos debates em documentos formatados, como artigos ou livros, com a ajuda dos assistentes de IA.\n",
      "\n",
      "6. **Constru√ß√£o de Consenso**: Identifique novos pontos de converg√™ncia e expresse suas ideias em propostas que refletem o consenso da sua comunidade.\n",
      "\n",
      "Se precisar de mais informa√ß√µes ou detalhes sobre alguma funcionalidade espec√≠fica, √© s√≥ perguntar! üòä"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "url = 'https://strateegia.digital'\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "data = [p.get_text() for p in soup.find_all('p')]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents([Document(page_content=str(data))])\n",
    "\n",
    "\n",
    "vectorstore = FAISS.from_documents(all_splits, OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "system_template = \"\"\"Voc√™ √© um bot de ajuda sobre a plataforma strateegia. Responda as perguntas do usu√°rio de maneira amig√°vel e se mantendo apenas sobre a plataforma..\n",
    "\n",
    "Pergunta: {question}\n",
    "\n",
    "Contexto: {context}\n",
    "\n",
    "Resposta:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(system_template)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "rag_chain = (\n",
    "     {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "for chunk in rag_chain.stream(\"Quais s√£o as principais funcionalidades do Strateegia?\"):\n",
    "    print(chunk, end=\"\", flush=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
