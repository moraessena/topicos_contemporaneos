{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando PyTorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao PyTorch\n",
    "\n",
    "## O que é PyTorch?\n",
    "PyTorch é uma biblioteca de aprendizado profundo de código aberto desenvolvida pelo Facebook's AI Research lab (FAIR). Ela é amplamente utilizada para tarefas de visão computacional e processamento de linguagem natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### História e contexto\n",
    "PyTorch foi lançado em janeiro de 2017. Ele é baseado na biblioteca Torch, que é uma estrutura de aprendizado de máquina em Lua. PyTorch é conhecido por sua facilidade de uso e integração com Python, o que o torna popular entre pesquisadores e engenheiros.\n",
    "\n",
    "### Comparação com outras bibliotecas\n",
    "- **TensorFlow**: Desenvolvido pelo Google, TensorFlow é uma das bibliotecas de aprendizado profundo mais populares. Enquanto TensorFlow é conhecido por sua escalabilidade e produção, PyTorch é elogiado por sua facilidade de uso e flexibilidade.\n",
    "- **NumPy**: NumPy é uma biblioteca fundamental para computação científica em Python. PyTorch usa tensores, que são similares aos arrays do NumPy, mas com suporte para computação em GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que são tensores?\n",
    "Tensores são a estrutura de dados fundamental em PyTorch. Eles são similares aos arrays do NumPy, mas com suporte para computação em GPU.\n",
    "\n",
    "Tensores 1D, 2D, 3D, etc.\n",
    "- 1D: Vetores\n",
    "- 2D: Matrizes\n",
    "- 3D: Matrizes tridimensionais (cubos de dados)\n",
    "- ND: Tensores de N dimensões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Tensor 1D\n",
    "tensor_1d = torch.tensor([1, 2, 3, 4])\n",
    "print(tensor_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor 2D\n",
    "tensor_2d = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(tensor_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor 3D\n",
    "tensor_3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print(tensor_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de dados\n",
    "Os tensores em PyTorch suportam vários tipos de dados, como inteiros e floats. O tipo de dado pode ser especificado durante a criação do tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Criação de um tensor de inteiros\n",
    "tensor_int = torch.tensor([1, 2, 3], dtype=torch.int32)\n",
    "print(tensor_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "# Criação de um tensor de floats\n",
    "tensor_float = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "print(tensor_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Criação de Tensores\n",
    "PyTorch fornece várias funções utilitárias para criar tensores de forma eficiente.\n",
    "\n",
    "- `torch.zeros`: Cria um tensor preenchido com zeros.\n",
    "- `torch.zeros_like`: Cria um tensor preenchido com zeros, com as mesmas dimensões de um tensor dado.\n",
    "- `torch.ones`: Cria um tensor preenchido com uns.\n",
    "- `torch.ones_like`: Cria um tensor preenchido com uns, com as mesmas dimensões de um tensor dado.\n",
    "- `torch.linspace`: Cria um tensor com valores linearmente espaçados entre dois pontos.\n",
    "- `torch.arange`: Cria um tensor com valores em uma faixa específica com um passo definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# Criação de tensores de zeros\n",
    "tensor_zeros = torch.zeros(3, 3, 5)\n",
    "print(tensor_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Criação de tensores de zeros_like\n",
    "tensor_zeros_like = torch.zeros_like(tensor_2d)\n",
    "print(tensor_zeros_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Criação de tensores de uns\n",
    "tensor_ones = torch.ones(2, 2)\n",
    "print(tensor_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Criação de tensores de ones_like\n",
    "tensor_ones_like = torch.ones_like(tensor_2d)\n",
    "print(tensor_ones_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])\n"
     ]
    }
   ],
   "source": [
    "# Linspace\n",
    "tensor_linspace = torch.linspace(0, 10, steps=5)\n",
    "print(tensor_linspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 2.5000, 5.0000, 7.5000])\n"
     ]
    }
   ],
   "source": [
    "# Arange\n",
    "tensor_arange = torch.arange(0, 10, step=2.5)\n",
    "print(tensor_arange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexação e Fatiamento\n",
    "A indexação e o fatiamento em PyTorch são similares ao NumPy, permitindo acessar e modificar partes específicas de um tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor original:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Criando um tensor de exemplo\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"Tensor original:\\n\", tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento na posição [1, 2]: tensor(6)\n"
     ]
    }
   ],
   "source": [
    "# Indexação por elementos específicos\n",
    "print(\"Elemento na posição [1, 2]:\", tensor[1, 2])  # Acessa o valor '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeira linha: tensor([1, 2, 3])\n",
      "Segunda coluna: tensor([2, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "# Indexação\n",
    "print(\"Primeira linha:\", tensor[0, :])  # Obtendo a primeira linha\n",
    "print(\"Segunda coluna:\", tensor[:, 1])  # Obtendo a segunda coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtensor a partir da segunda linha e segunda coluna:\n",
      " tensor([[5, 6],\n",
      "        [8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Fatiamento\n",
    "print(\"Subtensor a partir da segunda linha e segunda coluna:\\n\", tensor[1:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtensor pulando uma linha e uma coluna:\n",
      " tensor([[1, 3],\n",
      "        [7, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de fatiamento complexo: pulando elementos\n",
    "print(\"Subtensor pulando uma linha e uma coluna:\\n\", tensor[::2, ::2])  # Pulando linhas e colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Última linha do tensor: tensor([7, 8, 9])\n",
      "Última coluna do tensor: tensor([3, 6, 9])\n"
     ]
    }
   ],
   "source": [
    "# Fatiamento com valores negativos\n",
    "print(\"Última linha do tensor:\", tensor[-1, :])  # Acessando a última linha\n",
    "print(\"Última coluna do tensor:\", tensor[:, -1])  # Acessando a última coluna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operações básicas com tensores\n",
    "PyTorch suporta várias operações básicas com tensores, como adição, multiplicação, subtração e divisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ tensor([5, 7, 9])\n",
      "* tensor([ 4, 10, 18])\n",
      "- tensor([-3, -3, -3])\n",
      "/ tensor([0.2500, 0.4000, 0.5000])\n",
      "Produto escalar tensor(32)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "# Adição\n",
    "print(\"+\", a + b)\n",
    "\n",
    "# Multiplicação\n",
    "print(\"*\", a * b)\n",
    "\n",
    "# Subtração\n",
    "print(\"-\", a - b)\n",
    "\n",
    "# Divisão\n",
    "print(\"/\", a / b)\n",
    "\n",
    "# Produto escalar\n",
    "dot_product = torch.dot(a, b)\n",
    "print(\"Produto escalar\", dot_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulando formato (shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(12).reshape(4, 3)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1],\n",
      "        [ 2,  3],\n",
      "        [ 4,  5],\n",
      "        [ 6,  7],\n",
      "        [ 8,  9],\n",
      "        [10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# View\n",
    "tensor_reshaped = tensor.view(6, 2)\n",
    "print(tensor_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  3,  6,  9],\n",
      "        [ 1,  4,  7, 10],\n",
      "        [ 2,  5,  8, 11]])\n"
     ]
    }
   ],
   "source": [
    "# Transpose\n",
    "tensor_transposed = tensor.t()\n",
    "print(tensor_transposed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten\n",
    "A função flatten retorna um tensor 1D contendo todos os elementos do tensor original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n"
     ]
    }
   ],
   "source": [
    "# Flatten\n",
    "tensor_flattened = tensor.flatten()\n",
    "print(tensor_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0],\n",
      "          [ 1],\n",
      "          [ 2],\n",
      "          [ 3],\n",
      "          [ 4],\n",
      "          [ 5]],\n",
      "\n",
      "         [[ 6],\n",
      "          [ 7],\n",
      "          [ 8],\n",
      "          [ 9],\n",
      "          [10],\n",
      "          [11]]]])\n",
      "torch.Size([1, 2, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "# Reshape\n",
    "tensor_reshaped = tensor.reshape(1, 2, 6, 1)\n",
    "print(tensor_reshaped)\n",
    "print(tensor_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze e Unsqueeze\n",
    "- `squeeze`: Remove dimensões de tamanho 1 de um tensor.\n",
    "- `unsqueeze`: Adiciona uma dimensão de tamanho 1 em um tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n",
      "torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "# Squeeze\n",
    "tensor_squeezed = tensor_reshaped.squeeze()\n",
    "print(tensor_squeezed)\n",
    "print(tensor_squeezed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3,  4,  5],\n",
      "         [ 6,  7,  8,  9, 10, 11]]])\n",
      "torch.Size([1, 2, 6])\n"
     ]
    }
   ],
   "source": [
    "# Unsqueeze\n",
    "tensor_unsqueezed = tensor_squeezed.unsqueeze(dim=0)\n",
    "print(tensor_unsqueezed)\n",
    "print(tensor_unsqueezed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "O broadcasting é uma técnica que permite que tensores de diferentes formas sejam utilizados juntos em operações aritméticas. Em vez de copiar dados, o PyTorch ajusta os tensores de forma automática para que tenham formas compatíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adição de um Escalar\n",
    "\n",
    "Quando adicionamos um escalar a um tensor, o escalar é automaticamente expandido para a forma do tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 12, 13],\n",
      "        [14, 15, 16]])\n"
     ]
    }
   ],
   "source": [
    "# Cria um tensor 2x3\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Adiciona um escalar\n",
    "scalar = 10\n",
    "\n",
    "# Broadcasting para adicionar o escalar a cada elemento do tensor\n",
    "result = tensor + scalar\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adição de Tensores com Diferentes Dimensões\n",
    "\n",
    "Vamos adicionar um tensor 2x3 com um tensor 1x3. Neste caso, o tensor 1x3 será expandido (broadcasted) para uma forma 2x3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 22, 33],\n",
      "        [14, 25, 36]])\n"
     ]
    }
   ],
   "source": [
    "# Cria um tensor 2x3\n",
    "tensor_a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Cria um tensor 1x3\n",
    "tensor_b = torch.tensor([10, 20, 30])\n",
    "\n",
    "# Broadcasting para adicionar tensores de diferentes formas\n",
    "result = tensor_a + tensor_b\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regras de Broadcasting\n",
    "\n",
    "Para que o broadcasting funcione, os tensores devem seguir algumas regras:\n",
    "\n",
    "1. **Compatibilidade de Dimensões**: As dimensões dos tensores devem ser compatíveis. Duas dimensões são compatíveis se forem iguais ou se uma delas for 1.\n",
    "2. **Expansão Automática**: Se uma dimensão de um tensor for 1, ela será expandida para corresponder à dimensão do outro tensor.\n",
    "\n",
    "No exemplo a seguir, o tensor `tensor_c` de forma 2x1 é expandido para 2x3, e o tensor `tensor_d` de forma 1x3 é expandido para 2x3. O resultado é um tensor 2x3 onde cada elemento é o produto dos elementos correspondentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10, 20, 30],\n",
      "        [20, 40, 60]])\n"
     ]
    }
   ],
   "source": [
    "# Cria um tensor 2x1\n",
    "tensor_c = torch.tensor([[1], [2]])\n",
    "\n",
    "# Cria um tensor 1x3\n",
    "tensor_d = torch.tensor([10, 20, 30])\n",
    "\n",
    "# Broadcasting para multiplicar tensores de diferentes formas\n",
    "result = tensor_c * tensor_d\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operações de Redução em PyTorch\n",
    "\n",
    "As operações de redução são usadas para reduzir as dimensões de um tensor, aplicando operações como soma, média, mínimo e máximo. Essas operações são fundamentais em várias aplicações de machine learning e deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor original:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Cria um tensor 2x3\n",
    "tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "print(\"Tensor original:\\n\", tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soma de Todos os Elementos\n",
    "\n",
    "A função `torch.sum` calcula a soma de todos os elementos do tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soma de todos os elementos: 21.0\n"
     ]
    }
   ],
   "source": [
    "# Soma de todos os elementos do tensor\n",
    "sum_all = torch.sum(tensor)\n",
    "print(\"Soma de todos os elementos:\", sum_all.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soma ao Longo de um Eixo\n",
    "\n",
    "Podemos calcular a soma ao longo de um eixo específico, usando o parâmetro `dim`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soma ao longo do eixo 0 (linhas): tensor([5., 7., 9.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Soma ao longo do eixo 0 (linhas)\n",
    "sum_dim0 = torch.sum(tensor, axis=0)\n",
    "print(\"Soma ao longo do eixo 0 (linhas):\", sum_dim0)\n",
    "print(sum_dim0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soma ao longo do eixo 1 (colunas): tensor([ 6., 15.])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Soma ao longo do eixo 1 (colunas)\n",
    "sum_dim1 = torch.sum(tensor, dim=1)\n",
    "print(\"Soma ao longo do eixo 1 (colunas):\", sum_dim1)\n",
    "print(sum_dim1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Média dos Elementos\n",
    "\n",
    "A função `torch.mean` calcula a média dos elementos do tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média de todos os elementos: 3.5\n"
     ]
    }
   ],
   "source": [
    "# Média de todos os elementos do tensor\n",
    "mean_all = torch.mean(tensor)\n",
    "print(\"Média de todos os elementos:\", mean_all.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ao longo do eixo 0 (linhas): tensor([2.5000, 3.5000, 4.5000])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Média ao longo do eixo 0 (linhas)\n",
    "mean_dim0 = torch.mean(tensor, dim=0)\n",
    "print(\"Média ao longo do eixo 0 (linhas):\", mean_dim0)\n",
    "print(mean_dim0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ao longo do eixo 1 (colunas): tensor([2., 5.])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Média ao longo do eixo 1 (colunas)\n",
    "mean_dim1 = torch.mean(tensor, dim=1)\n",
    "print(\"Média ao longo do eixo 1 (colunas):\", mean_dim1)\n",
    "print(mean_dim1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valor Mínimo e Máximo\n",
    "\n",
    "Podemos encontrar o valor mínimo e máximo de um tensor usando `torch.min` e `torch.max`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor mínimo de todos os elementos: tensor(1.)\n",
      "\n",
      "Valor máximo de todos os elementos: tensor(6.)\n",
      "\n",
      "Valor mínimo ao longo do eixo 0 (linhas): tensor([1., 2., 3.])\n",
      "Índices dos valores mínimos ao longo do eixo 0 (linhas): tensor([0, 0, 0])\n",
      "\n",
      "Valor máximo ao longo do eixo 1 (colunas): tensor([3., 6.])\n",
      "Índices dos valores máximos ao longo do eixo 1 (colunas): tensor([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Valor mínimo de todos os elementos do tensor\n",
    "min_all = torch.min(tensor)\n",
    "print(\"Valor mínimo de todos os elementos:\", min_all)\n",
    "print()\n",
    "\n",
    "# Valor máximo de todos os elementos do tensor\n",
    "max_all = torch.max(tensor)\n",
    "print(\"Valor máximo de todos os elementos:\", max_all)\n",
    "print()\n",
    "\n",
    "# Valor mínimo ao longo do eixo 0 (linhas)\n",
    "min_dim0, min_indices_dim0 = torch.min(tensor, dim=0)\n",
    "print(\"Valor mínimo ao longo do eixo 0 (linhas):\", min_dim0)\n",
    "print(\"Índices dos valores mínimos ao longo do eixo 0 (linhas):\", min_indices_dim0)\n",
    "print()\n",
    "\n",
    "# Valor máximo ao longo do eixo 1 (colunas)\n",
    "max_dim1, max_indices_dim1 = torch.max(tensor, dim=1)\n",
    "print(\"Valor máximo ao longo do eixo 1 (colunas):\", max_dim1)\n",
    "print(\"Índices dos valores máximos ao longo do eixo 1 (colunas):\", max_indices_dim1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produto dos Elementos\n",
    "\n",
    "A função `torch.prod` calcula o produto de todos os elementos do tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produto de todos os elementos: tensor(720.)\n",
      "\n",
      "Produto ao longo do eixo 0 (linhas): tensor([ 4., 10., 18.])\n",
      "\n",
      "Produto ao longo do eixo 1 (colunas): tensor([  6., 120.])\n"
     ]
    }
   ],
   "source": [
    "# Produto de todos os elementos do tensor\n",
    "prod_all = torch.prod(tensor)\n",
    "print(\"Produto de todos os elementos:\", prod_all)\n",
    "print()\n",
    "\n",
    "# Produto ao longo do eixo 0 (linhas)\n",
    "prod_dim0 = torch.prod(tensor, dim=0)\n",
    "print(\"Produto ao longo do eixo 0 (linhas):\", prod_dim0)\n",
    "print()\n",
    "\n",
    "# Produto ao longo do eixo 1 (colunas)\n",
    "prod_dim1 = torch.prod(tensor, dim=1)\n",
    "print(\"Produto ao longo do eixo 1 (colunas):\", prod_dim1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propriedade requires_grad\n",
    "A propriedade `requires_grad` em PyTorch é fundamental para a construção e treinamento de redes neurais, pois permite calcular automaticamente os gradientes das operações. Quando `requires_grad` é definido como `True` em um tensor, todas as operações feitas nesse tensor serão rastreadas para a diferenciação automática.\n",
    "\n",
    "### Autograd e Grafos Computacionais\n",
    "\n",
    "Autograd é um componente essencial em frameworks de deep learning como PyTorch, que permite a diferenciação automática de tensores. Este mecanismo é fundamental para a otimização dos modelos de aprendizado de máquina, pois permite calcular gradientes de forma eficiente, necessária para o ajuste dos parâmetros do modelo durante o treinamento.\n",
    "\n",
    "#### Grafos Computacionais\n",
    "\n",
    "Para entender o funcionamento do autograd, é importante compreender os grafos computacionais. Um grafo computacional é uma representação gráfica de uma sequência de operações matemáticas, onde:\n",
    "\n",
    "- **Nós (nodes)** representam operações matemáticas ou variáveis.\n",
    "- **Arestas (edges)** representam os fluxos de dados (tensores) entre as operações.\n",
    "\n",
    "![alt text](https://miro.medium.com/max/908/1*ahiviCqq6B0R_XWBmgvHkA.png \"Grafo Computacional\")\n",
    "\n",
    "Durante a construção de um modelo, as operações realizadas nos tensores criam um grafo computacional dinâmico, também conhecido como *Dynamic Computation Graph*. Esse grafo é dinâmico porque é construído à medida que as operações são executadas, permitindo flexibilidade e facilidade na criação e modificação de modelos.\n",
    "\n",
    "#### Propagação para Frente (Forward Pass)\n",
    "\n",
    "Durante a propagação para frente (forward pass), os tensores são passados através das operações definidas no grafo computacional, produzindo uma saída. Este processo é usado para calcular a perda (loss) do modelo.\n",
    "\n",
    "#### Propagação para Trás (Backward Pass)\n",
    "\n",
    "A propagação para trás (backward pass) é o processo de calcular os gradientes dos tensores em relação à perda, utilizando a regra da cadeia. O autograd facilita essa tarefa, realizando automaticamente a diferenciação reversa ao longo do grafo computacional. Os passos são:\n",
    "\n",
    "1. **Calcula a perda**: A partir das saídas do forward pass.\n",
    "2. **Calcula os gradientes**: Utilizando a diferenciação automática.\n",
    "3. **Atualiza os parâmetros**: Os gradientes calculados são usados para ajustar os parâmetros do modelo através de otimização, como o gradiente descendente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando Tensores com `requires_grad`\n",
    "\n",
    "Vamos criar tensores com a propriedade `requires_grad` definida como `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Tensor com requires_grad\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizando Operações com Tensores que Têm `requires_grad`\n",
    "\n",
    "Quando realizamos operações com tensores que têm `requires_grad=True`, o PyTorch cria uma tape (fita) para rastrear todas as operações. Vamos ver um exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Realiza uma operação com o tensor x\n",
    "y = x ** 2\n",
    "\n",
    "# Mais uma operação\n",
    "z = y.sum()\n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando Gradientes\n",
    "\n",
    "Para calcular os gradientes, usamos o método `backward()`. Isso calcula o gradiente da função de perda em relação a todos os tensores que têm `requires_grad=True`.\n",
    "\n",
    "Os gradientes armazenados em `x.grad` representam a derivada da soma `z` em relação a `x`. Como `z` é a soma dos elementos de `y` e `y = x ** 2`, a derivada de `z` em relação a `x` é `2 * x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 6.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/Documentos/dados/projetos/16 - Topicos Contemporaneos/topicos_contemporaneos/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:825: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "# Calcula os gradientes\n",
    "z.backward()\n",
    "\n",
    "# z = x1² + x2² + x3²\n",
    "# dz/x1 = 2x1\n",
    "\n",
    "# Imprime os gradientes armazenados em x.grad\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desativando o Rastreamento de Gradientes\n",
    "\n",
    "Em algumas situações, não queremos rastrear as operações, como durante a inferência do modelo. Podemos desativar temporariamente o rastreamento de gradientes usando `torch.no_grad()` ou `detach()`. Vamos ver como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Desativando o rastreamento de gradientes temporariamente\n",
    "with torch.no_grad():\n",
    "    y = x * 2\n",
    "    print(y.requires_grad)  # False, pois o rastreamento está desativado\n",
    "\n",
    "# Criando um novo tensor sem rastreamento de gradientes\n",
    "x_detached = x.detach()\n",
    "print(x_detached.requires_grad)  # False, pois o tensor foi separado da tape de computação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando se um Tensor Requer Gradiente\n",
    "\n",
    "Podemos verificar se um tensor requer gradiente usando a propriedade `requires_grad`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)  # True, pois x foi criado com requires_grad=True\n",
    "print(x_detached.requires_grad)  # False, pois x_detached foi separado da tape de computação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios - PyTorch Básico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1: Criação de Tensores\n",
    "\n",
    "1. Crie um tensor 1D com os valores de 1 a 10.\n",
    "2. Crie um tensor 2D de forma (3, 3) com valores aleatórios.\n",
    "3. Crie um tensor 3D de forma (2, 3, 4) com todos os valores iguais a 1.\n",
    "4. Crie um tensor de zeros com as mesmas dimensões do tensor 2D criado no exercício 2.\n",
    "5. Crie um tensor de uns com as mesmas dimensões do tensor 3D criado no exercício 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor 1: tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "Tensor 2: tensor([[0.2705, 0.3507, 0.2433],\n",
      "        [0.3452, 0.5145, 0.9065],\n",
      "        [0.6008, 0.4451, 0.2991]])\n",
      "Tensor 3: tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "Tensor 4 (Zeros com a forma de Tensor 2): tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Tensor 5 (Uns com a forma de Tensor 3): tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "# 1. Crie um tensor 1D com os valores de 1 a 10.\n",
    "tensor1 = torch.arange(1, 11)\n",
    "print(\"Tensor 1:\", tensor1)\n",
    "\n",
    "# 2. Crie um tensor 2D de forma (3, 3) com valores aleatórios.\n",
    "tensor2 = torch.rand(3, 3)  # Valores aleatórios entre 0 e 1\n",
    "print(\"Tensor 2:\", tensor2)\n",
    "\n",
    "# 3. Crie um tensor 3D de forma (2, 3, 4) com todos os valores iguais a 1.\n",
    "tensor3 = torch.ones(2, 3, 4)\n",
    "print(\"Tensor 3:\", tensor3)\n",
    "\n",
    "# 4. Crie um tensor de zeros com as mesmas dimensões do tensor 2D criado no exercício 2.\n",
    "tensor4 = torch.zeros_like(tensor2)\n",
    "print(\"Tensor 4 (Zeros com a forma de Tensor 2):\", tensor4)\n",
    "\n",
    "# 5. Crie um tensor de uns com as mesmas dimensões do tensor 3D criado no exercício 3.\n",
    "tensor5 = torch.ones_like(tensor3)\n",
    "print(\"Tensor 5 (Uns com a forma de Tensor 3):\", tensor5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2: Manipulação de Tensores\n",
    "\n",
    "1. Dado o tensor `a = torch.tensor([[1, 2], [3, 4], [5, 6]])`, obtenha a primeira coluna.\n",
    "2. Dado o tensor `b = torch.tensor([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])`, obtenha o subtensor `[[7, 8, 9], [10, 11, 12]]`.\n",
    "3. Dado o tensor `c = torch.tensor([1, 2, 3, 4, 5, 6])`, mude sua forma para (2, 3).\n",
    "4. Dado o tensor `d = torch.tensor([1, 2, 3, 4, 5, 6])`, adicione uma dimensão extra para que ele se torne de forma (1, 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Primeira coluna de a: tensor([1, 3, 5])\n",
      "2. Subtensor de b: tensor([[ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      "3. Tensor c reformatado para (2, 3): tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "4. Tensor d com forma (1, 6): tensor([[1, 2, 3, 4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# 1. Obtenha a primeira coluna do tensor `a`.\n",
    "a = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "first_column = a[:, 0]\n",
    "print(\"1. Primeira coluna de a:\", first_column)\n",
    "\n",
    "# 2. Obtenha o subtensor `[[7, 8, 9], [10, 11, 12]]` do tensor `b`.\n",
    "b = torch.tensor([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "subtensor = b[1]\n",
    "print(\"2. Subtensor de b:\", subtensor)\n",
    "\n",
    "# 3. Mude a forma de `c` para (2, 3).\n",
    "c = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "reshaped_c = c.view(2, 3)  # Ou c.reshape(2, 3)\n",
    "print(\"3. Tensor c reformatado para (2, 3):\", reshaped_c)\n",
    "\n",
    "# 4. Adicione uma dimensão extra a `d` para que ele se torne de forma (1, 6).\n",
    "d = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "expanded_d = d.unsqueeze(0)  # Adiciona a dimensão no eixo 0\n",
    "print(\"4. Tensor d com forma (1, 6):\", expanded_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3: Funções de Criação de Tensores\n",
    "\n",
    "1. Crie um tensor contendo valores de 0 a 1, espaçados igualmente em 5 passos.\n",
    "2. Crie um tensor contendo valores de 0 a 10, com um passo de 2.\n",
    "3. Crie um tensor de forma (3, 3) com valores aleatórios entre 0 e 10.\n",
    "4. Crie um tensor correspondente a uma imagem em escala de cinza de dimensões 128x128 com valores aleatórios entre 0 e 255.\n",
    "5. Crie um tensor correspondente a uma imagem em RGB de dimensões 128x128 com valores aleatórios entre 0 e 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor 1: tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n",
      "Tensor 2: tensor([ 0,  2,  4,  6,  8, 10])\n",
      "Tensor 3: tensor([[5, 8, 8],\n",
      "        [8, 9, 7],\n",
      "        [9, 0, 9]])\n",
      "Tensor 4 (Gray Image): tensor([[ 50, 117, 114,  ...,  28,  55, 254],\n",
      "        [151, 221,  16,  ..., 123, 250, 140],\n",
      "        [ 39, 164, 127,  ...,  47,  64,  90],\n",
      "        ...,\n",
      "        [126,  81, 243,  ...,  90, 140, 115],\n",
      "        [ 69, 250, 191,  ..., 106,  20, 171],\n",
      "        [181,  17, 156,  ..., 210,   3,  33]], dtype=torch.uint8)\n",
      "Tensor 5 (RGB Image): tensor([[[161, 204, 194],\n",
      "         [197, 233,  36],\n",
      "         [244, 247, 127],\n",
      "         ...,\n",
      "         [128, 172, 214],\n",
      "         [235, 201, 222],\n",
      "         [ 20,  58,  41]],\n",
      "\n",
      "        [[ 80, 189,  77],\n",
      "         [ 72, 210, 205],\n",
      "         [ 54, 143,  67],\n",
      "         ...,\n",
      "         [ 55, 209, 104],\n",
      "         [223, 112, 209],\n",
      "         [ 75, 191, 159]],\n",
      "\n",
      "        [[174,  76,  71],\n",
      "         [190, 157, 203],\n",
      "         [ 12,  34, 186],\n",
      "         ...,\n",
      "         [196, 115, 197],\n",
      "         [  9,  49, 148],\n",
      "         [ 82, 114,  34]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[227, 210, 219],\n",
      "         [135,  56,   2],\n",
      "         [191,  69, 106],\n",
      "         ...,\n",
      "         [ 94, 194,   9],\n",
      "         [143,  82,  17],\n",
      "         [118,  28, 133]],\n",
      "\n",
      "        [[108,  90, 242],\n",
      "         [ 75, 173, 193],\n",
      "         [184, 105, 221],\n",
      "         ...,\n",
      "         [ 49,  95, 190],\n",
      "         [ 69, 252,  93],\n",
      "         [103, 235, 142]],\n",
      "\n",
      "        [[207,  31, 131],\n",
      "         [160, 149,   5],\n",
      "         [ 27, 236, 251],\n",
      "         ...,\n",
      "         [ 42, 165,  89],\n",
      "         [ 97,  75, 241],\n",
      "         [202, 193, 250]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# 1. Crie um tensor contendo valores de 0 a 1, espaçados igualmente em 5 passos.\n",
    "tensor1 = torch.linspace(0, 1, steps=5)\n",
    "print(\"Tensor 1:\", tensor1)\n",
    "\n",
    "# 2. Crie um tensor contendo valores de 0 a 10, com um passo de 2.\n",
    "tensor2 = torch.arange(0, 11, step=2)  # Inclui 10\n",
    "print(\"Tensor 2:\", tensor2)\n",
    "\n",
    "# 3. Crie um tensor de forma (3, 3) com valores aleatórios entre 0 e 10.\n",
    "tensor3 = torch.randint(0, 11, (3, 3))  # 0 a 10 inclusivo\n",
    "print(\"Tensor 3:\", tensor3)\n",
    "\n",
    "# 4. Crie um tensor correspondente a uma imagem em escala de cinza de dimensões 128x128 com valores aleatórios entre 0 e 255.\n",
    "tensor4 = torch.randint(0, 256, (128, 128), dtype=torch.uint8)  # Usando dtype uint8 para simular uma imagem\n",
    "print(\"Tensor 4 (Gray Image):\", tensor4)\n",
    "\n",
    "# 5. Crie um tensor correspondente a uma imagem em RGB de dimensões 128x128 com valores aleatórios entre 0 e 255.\n",
    "tensor5 = torch.randint(0, 256, (128, 128, 3), dtype=torch.uint8)  # Última dimensão representa as 3 cores (RGB)\n",
    "print(\"Tensor 5 (RGB Image):\", tensor5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4: Operações Avançadas com Tensores\n",
    "\n",
    "1. Dado o tensor `a = torch.tensor([1, 2, 3])` e `b = torch.tensor([[4], [5], [6]])`, calcule a soma de `a` e `b` usando broadcasting.\n",
    "2. Dado o tensor `a = torch.tensor([1.0, 2.0, 3.0, 4.0])`, calcule a soma de todos os elementos.\n",
    "3. Dado o tensor `a = torch.tensor([1.0, 2.0, 3.0, 4.0])`, calcule a média de todos os elementos.\n",
    "4. Dado o tensor `a = torch.tensor([1.0, 2.0, 3.0, 4.0])`, calcule a raiz quadrada de todos os elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Soma de a e b usando broadcasting:\n",
      " tensor([[5, 6, 7],\n",
      "        [6, 7, 8],\n",
      "        [7, 8, 9]])\n",
      "2. Soma de todos os elementos de a: tensor(10.)\n",
      "3. Média de todos os elementos de a: tensor(2.5000)\n",
      "4. Raiz quadrada de todos os elementos de a:\n",
      " tensor([1.0000, 1.4142, 1.7321, 2.0000])\n"
     ]
    }
   ],
   "source": [
    "# 1. Soma de `a` e `b` usando broadcasting.\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([[4], [5], [6]])\n",
    "sum_ab = a + b\n",
    "print(\"1. Soma de a e b usando broadcasting:\\n\", sum_ab)\n",
    "\n",
    "# 2. Soma de todos os elementos do tensor `a`.\n",
    "a = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "sum_a = a.sum()\n",
    "print(\"2. Soma de todos os elementos de a:\", sum_a)\n",
    "\n",
    "# 3. Média de todos os elementos do tensor `a`.\n",
    "mean_a = a.mean()\n",
    "print(\"3. Média de todos os elementos de a:\", mean_a)\n",
    "\n",
    "# 4. Raiz quadrada de todos os elementos do tensor `a`.\n",
    "sqrt_a = a.sqrt()\n",
    "print(\"4. Raiz quadrada de todos os elementos de a:\\n\", sqrt_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 5: Autograd e Backpropagation\n",
    "\n",
    "1. Crie um tensor `x` com os valores `[2.0, 3.0]` e `requires_grad=True`. Calcule `y = x^2` e os gradientes.\n",
    "2. Crie um tensor `x` com o valor `3.0` e `requires_grad=True`. Calcule `y = 2*x + 1` e o gradiente.\n",
    "3. Crie um tensor `x` com os valores `[1.0, 2.0, 3.0]` e `requires_grad=True`. Calcule `y = x^3` e os gradientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Gradientes de x1: tensor([4., 6.])\n",
      "2. Gradiente de x2: tensor(2.)\n",
      "3. Gradientes de x3: tensor([ 3., 12., 27.])\n"
     ]
    }
   ],
   "source": [
    "# 1. Tensor x com `requires_grad=True`, calcule y = x^2 e os gradientes.\n",
    "x1 = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "y1 = x1 ** 2  # Calcula y = x^2\n",
    "y1.backward(torch.tensor([1.0, 1.0]))  # Propaga os gradientes\n",
    "print(\"1. Gradientes de x1:\", x1.grad)\n",
    "\n",
    "# 2. Tensor x com `requires_grad=True`, calcule y = 2*x + 1 e o gradiente.\n",
    "x2 = torch.tensor(3.0, requires_grad=True)\n",
    "y2 = 2 * x2 + 1  # Calcula y = 2*x + 1\n",
    "y2.backward()  # Propaga o gradiente\n",
    "print(\"2. Gradiente de x2:\", x2.grad)\n",
    "\n",
    "# 3. Tensor x com `requires_grad=True`, calcule y = x^3 e os gradientes.\n",
    "x3 = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y3 = x3 ** 3  # Calcula y = x^3\n",
    "y3.backward(torch.ones_like(x3))  # Propaga os gradientes\n",
    "print(\"3. Gradientes de x3:\", x3.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 6: Operações de Redução\n",
    "\n",
    "1. Crie um tensor de forma (4, 5) contendo valores de 1 a 20 usando `torch.arange`. Em seguida, calcule a soma de todos os elementos do tensor.\n",
    "2. Crie um tensor de forma (3, 4) com valores aleatórios entre 0 e 1 usando `torch.rand`. Calcule a média dos elementos ao longo do eixo 1 (colunas).\n",
    "3. Crie um tensor de forma (5, 5) contendo valores espaçados igualmente de 0 a 24 usando `torch.linspace`. Encontre o valor mínimo e o máximo de todos os elementos do tensor.\n",
    "4. Crie um tensor de forma (3, 6) com valores inteiros aleatórios entre 10 e 50 usando `torch.randint`. Calcule o produto dos elementos ao longo do eixo 0 (linhas).\n",
    "5. Crie um tensor de forma (2, 3, 4) com valores aleatórios entre 0 e 1 usando `torch.rand`. Encontre a soma dos elementos ao longo do eixo 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Soma de todos os elementos de tensor1: tensor(210)\n",
      "2. Média dos elementos de tensor2 ao longo do eixo 1: tensor([0.4037, 0.6897, 0.3055])\n",
      "3. Mínimo de tensor3: tensor(0.)\n",
      "   Máximo de tensor3: tensor(24.)\n",
      "4. Produto dos elementos de tensor4 ao longo do eixo 0: tensor([64974, 27232, 14112, 23940,  4092,  8664])\n",
      "5. Soma dos elementos de tensor5 ao longo do eixo 2:\n",
      " tensor([[2.1023, 2.6077, 1.6693],\n",
      "        [2.0820, 2.2422, 3.0220]])\n"
     ]
    }
   ],
   "source": [
    "# 1. Crie um tensor de forma (4, 5) com valores de 1 a 20 e calcule a soma de todos os elementos.\n",
    "tensor1 = torch.arange(1, 21).view(4, 5)\n",
    "sum_tensor1 = tensor1.sum()\n",
    "print(\"1. Soma de todos os elementos de tensor1:\", sum_tensor1)\n",
    "\n",
    "# 2. Crie um tensor de forma (3, 4) com valores aleatórios entre 0 e 1 e calcule a média ao longo do eixo 1.\n",
    "tensor2 = torch.rand(3, 4)\n",
    "mean_tensor2 = tensor2.mean(dim=1)  # Média ao longo das colunas\n",
    "print(\"2. Média dos elementos de tensor2 ao longo do eixo 1:\", mean_tensor2)\n",
    "\n",
    "# 3. Crie um tensor de forma (5, 5) com valores espaçados igualmente de 0 a 24 e encontre o mínimo e máximo.\n",
    "tensor3 = torch.linspace(0, 24, steps=25).view(5, 5)\n",
    "min_tensor3 = tensor3.min()\n",
    "max_tensor3 = tensor3.max()\n",
    "print(\"3. Mínimo de tensor3:\", min_tensor3)\n",
    "print(\"   Máximo de tensor3:\", max_tensor3)\n",
    "\n",
    "# 4. Crie um tensor de forma (3, 6) com valores inteiros aleatórios entre 10 e 50 e calcule o produto ao longo do eixo 0.\n",
    "tensor4 = torch.randint(10, 50, (3, 6))\n",
    "prod_tensor4 = tensor4.prod(dim=0)  # Produto ao longo das linhas\n",
    "print(\"4. Produto dos elementos de tensor4 ao longo do eixo 0:\", prod_tensor4)\n",
    "\n",
    "# 5. Crie um tensor de forma (2, 3, 4) com valores aleatórios entre 0 e 1 e encontre a soma ao longo do eixo 2.\n",
    "tensor5 = torch.rand(2, 3, 4)\n",
    "sum_tensor5 = tensor5.sum(dim=2)  # Soma ao longo do eixo 2\n",
    "print(\"5. Soma dos elementos de tensor5 ao longo do eixo 2:\\n\", sum_tensor5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
